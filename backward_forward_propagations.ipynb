{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3lnTfSon3oxXunrPBasVu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kareemelhawaryy/AMIT/blob/main/backward_forward_propagations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "8R0TiuoCABkE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(Z):\n",
        "    return 1 / (1 + np.exp(-Z))\n",
        "\n",
        "def sigmoid_derivative(A):\n",
        "    return A * (1 - A)\n",
        "\n",
        "def relu(Z):\n",
        "    return np.maximum(0, Z)\n",
        "\n",
        "def relu_derivative(Z):\n",
        "    return Z > 0"
      ],
      "metadata": {
        "id": "9infOzDrABme"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_parameters(layer_dims):\n",
        "    np.random.seed(1)\n",
        "    parameters = {}\n",
        "    for l in range(1, len(layer_dims)):\n",
        "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l - 1]) * 0.01\n",
        "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
        "    return parameters"
      ],
      "metadata": {
        "id": "t8_Na0fcABpJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation(X, parameters):\n",
        "    caches = []\n",
        "    A = X\n",
        "    L = len(parameters) // 2\n",
        "\n",
        "    for l in range(1, L):\n",
        "        W = parameters['W' + str(l)]\n",
        "        b = parameters['b' + str(l)]\n",
        "        Z = np.dot(W, A) + b\n",
        "        A = relu(Z)\n",
        "        caches.append((A, W, b, Z))\n",
        "\n",
        "    W = parameters['W' + str(L)]\n",
        "    b = parameters['b' + str(L)]\n",
        "    Z = np.dot(W, A) + b\n",
        "    A = sigmoid(Z)\n",
        "    caches.append((A, W, b, Z))\n",
        "\n",
        "    return A, caches"
      ],
      "metadata": {
        "id": "972bnugfABrr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(AL, Y):\n",
        "    m = Y.shape[1]\n",
        "    cost = -np.sum(Y * np.log(AL + 1e-8) + (1 - Y) * np.log(1 - AL + 1e-8)) / m\n",
        "    return cost\n",
        "def backward_propagation(X, Y, caches, parameters):\n",
        "    grads = {}\n",
        "    L = len(caches)\n",
        "    m = X.shape[1]\n",
        "    AL, WL, bL, ZL = caches[-1]\n",
        "    dZ = AL - Y\n",
        "    A_prev = caches[-2][0] if L > 1 else X\n",
        "    grads['dW' + str(L)] = (1 / m) * np.dot(dZ, A_prev.T)\n",
        "    grads['db' + str(L)] = (1 / m) * np.sum(dZ, axis=1, keepdims=True)\n",
        "    dA_prev = np.dot(parameters['W' + str(L)].T, dZ)\n",
        "\n",
        "    for l in reversed(range(L - 1)):\n",
        "        A, W, b, Z = caches[l]\n",
        "        dZ = dA_prev * relu_derivative(Z)\n",
        "        A_prev = X if l == 0 else caches[l - 1][0]\n",
        "        grads['dW' + str(l + 1)] = (1 / m) * np.dot(dZ, A_prev.T)\n",
        "        grads['db' + str(l + 1)] = (1 / m) * np.sum(dZ, axis=1, keepdims=True)\n",
        "        dA_prev = np.dot(parameters['W' + str(l + 1)].T, dZ)\n",
        "\n",
        "    return grads"
      ],
      "metadata": {
        "id": "J0Fy3sfPABuD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_parameters(parameters, grads, learning_rate):\n",
        "    L = len(parameters) // 2\n",
        "    for l in range(1, L + 1):\n",
        "        parameters['W' + str(l)] -= learning_rate * grads['dW' + str(l)]\n",
        "        parameters['b' + str(l)] -= learning_rate * grads['db' + str(l)]\n",
        "    return parameters\n",
        "\n",
        "def model(X, Y, layers_dims, learning_rate=0.1, num_iterations=100):\n",
        "    parameters = initialize_parameters(layers_dims)\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        AL, caches = forward_propagation(X, parameters)\n",
        "        cost = compute_cost(AL, Y)\n",
        "        grads = backward_propagation(X, Y, caches, parameters)\n",
        "        parameters = update_parameters(parameters, grads, learning_rate)\n",
        "        if i % 10 == 0:\n",
        "            print(f\"Iteration {i}, cost: {cost:.4f}\")\n",
        "\n",
        "    return parameters"
      ],
      "metadata": {
        "id": "kc_srF3SABwk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[0, 0, 1, 1], [0, 1, 0, 1]])\n",
        "Y = np.array([[0, 1, 1, 0]])\n",
        "layers_dims = [2, 4, 3, 1]\n",
        "\n",
        "model(X, Y, layers_dims, learning_rate=1.0, num_iterations=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1Q0ZrGuABzN",
        "outputId": "e99daf3c-c8ce-4aa6-b012-4bf917782bca"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, cost: 0.6931\n",
            "Iteration 10, cost: 0.6931\n",
            "Iteration 20, cost: 0.6931\n",
            "Iteration 30, cost: 0.6931\n",
            "Iteration 40, cost: 0.6931\n",
            "Iteration 50, cost: 0.6931\n",
            "Iteration 60, cost: 0.6931\n",
            "Iteration 70, cost: 0.6931\n",
            "Iteration 80, cost: 0.6931\n",
            "Iteration 90, cost: 0.6931\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'W1': array([[ 0.01624345, -0.00556695],\n",
              "        [-0.00528172, -0.01072969],\n",
              "        [ 0.0068055 , -0.02301539],\n",
              "        [ 0.01744811, -0.01129289]]),\n",
              " 'b1': array([[ 5.51886960e-04],\n",
              "        [ 0.00000000e+00],\n",
              "        [ 5.86297704e-06],\n",
              "        [-2.83649428e-05]]),\n",
              " 'W2': array([[ 0.00242212, -0.0024937 ,  0.01355014, -0.0219077 ],\n",
              "        [-0.00322417, -0.00384054,  0.01133769, -0.01099891],\n",
              "        [-0.00107705, -0.00877858,  0.00132463,  0.00692215]]),\n",
              " 'b2': array([[ 0.00137573],\n",
              "        [-0.0014309 ],\n",
              "        [ 0.00112877]]),\n",
              " 'W3': array([[-0.01192305,  0.01144724,  0.00974575]]),\n",
              " 'b3': array([[3.96225887e-06]])}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}